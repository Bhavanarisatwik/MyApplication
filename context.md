Project Description

The system is a distributed, privacy-aware personal AI memory engine that passively captures spoken conversations on an Android device, converts them into structured semantic summaries, stores only compressed knowledge artifacts in user-owned cloud storage, and enables contextual retrieval through natural language questions. The system is designed to behave like a cognitive compression pipeline that listens selectively using voice activity detection, processes speech through controlled server orchestration, generates structured memory objects at hourly and daily intervals, and automatically enforces retention rules that delete raw and intermediate data while preserving only meaningful high-level knowledge.

The Android device acts as an edge capture node that detects speech and transmits short audio segments to an OpenClaw orchestration service. OpenClaw functions as a secure, ephemeral processing proxy that calls the Sarvam AI speech-to-text service, buffers transcripts temporarily, and triggers summarization models at scheduled boundaries. Persistent storage is never owned by the orchestration server. Instead, final structured summaries are returned to the client and uploaded directly to the user’s personal Google Drive using OAuth authentication, ensuring that long-term memory ownership remains entirely with the user. Retrieval queries are routed back through the orchestration service, which performs semantic matching over stored summaries and generates contextual answers.

High-Level System Structure

The architecture consists of four logical layers: the mobile capture layer, the orchestration proxy layer, the AI processing layer, and the user-owned storage and retrieval layer. The mobile layer is responsible for capturing speech intelligently and reliably. The orchestration proxy layer, implemented through OpenClaw, manages all secure API interactions and scheduling logic without retaining persistent data. The AI processing layer includes Sarvam AI for speech recognition and language models for summarization and question answering. The storage layer is implemented through the user’s Google Drive account, ensuring decentralized data ownership and strong privacy guarantees.

The complete pipeline begins with the Android foreground service listening to audio input through VAD. When speech is detected, short audio segments are captured and transmitted to the OpenClaw endpoint. OpenClaw immediately forwards the audio to Sarvam AI using secure server-side credentials. The returned transcript is appended to a temporary in-memory hourly buffer. At the end of each hour, OpenClaw invokes the summarization model with the buffered transcript, produces a structured semantic summary, clears the buffer, and returns the summary to the mobile client. The mobile application then uploads the summary directly into the user’s Google Drive. At daily boundaries, the client merges hourly summaries into a single daily knowledge artifact and stores it in Drive while deleting outdated intermediate summaries according to retention rules.

Procedural Flow to Follow

The correct procedure requires strict separation of responsibilities across layers to avoid circular dependencies or redundant processing. The mobile application must never directly call Sarvam AI for transcription because this would expose API credentials and create inconsistent orchestration logic. All transcription requests must pass through OpenClaw so that credential management, retry logic, and request normalization remain centralized and secure. OpenClaw must never persist transcripts or audio chunks to disk; buffering must be strictly in-memory and cleared immediately after summarization. Persistent storage must always be performed from the client side using user OAuth credentials so that no long-term memory artifacts are owned by the server infrastructure.

The system must enforce a deterministic sequence for each audio segment. The audio is captured locally, transmitted to OpenClaw, forwarded to Sarvam AI, converted to text, appended to the hourly buffer, summarized at the correct boundary, returned to the client, and then uploaded to Google Drive. No step should skip the orchestration proxy because this would break consistent scheduling and error management. Similarly, summarization must occur only once per hour per buffer to avoid duplicate summaries or conflicting memory objects.

Reverse queries initiated by the user must follow a controlled retrieval path. The mobile application sends the question to OpenClaw along with metadata such as date range or topic filters. OpenClaw fetches relevant summary artifacts either from a small synchronized index or through direct Drive queries, performs semantic similarity matching, and invokes the language model with only the matched context. The generated answer is returned to the client along with references to the time segments used. This ensures that reverse questioning is contextual, accurate, and traceable.

Professional Orchestration of Back-and-Forth API Calls

All API interactions must be sequenced and managed by OpenClaw as a centralized orchestrator. When the mobile app uploads audio, OpenClaw immediately acknowledges receipt and places the request in an asynchronous processing queue. It then triggers the Sarvam STT call and awaits the transcript response. If the STT service fails or times out, OpenClaw retries with exponential backoff while maintaining idempotent request identifiers to prevent duplicate processing. Once transcription succeeds, the result is appended to the hourly buffer and a processing acknowledgment is returned to the client.

At the hourly boundary, OpenClaw locks the current buffer, invokes the summarization model, and produces a structured JSON summary. This summary is returned to the client as the canonical artifact. After confirmation of receipt, OpenClaw clears the buffer memory to ensure ephemeral processing. This explicit acknowledgment cycle prevents race conditions where summaries might be generated multiple times or buffers might be cleared prematurely.

Reverse query API calls must also be orchestrated carefully. The client sends a query request, OpenClaw retrieves relevant summaries, performs semantic filtering, and only then invokes the answer generation model. The response must include provenance references to ensure transparency and debugging capability. Every API call must be idempotent and include correlation identifiers so that failures or retries do not create inconsistent states.

Issues and Failure Permutations to Manage

Network instability is one of the primary operational risks. Upload failures from the device may result in lost audio segments unless a retry queue with durable local caching is implemented. Sarvam API latency spikes can cause backlog accumulation, requiring asynchronous worker pools and queue management. Android background execution policies may suspend the capture service, so the foreground service must be carefully configured with persistent notifications and battery optimization exemptions.

Concurrency issues may occur when multiple audio chunks arrive near hourly boundaries. The system must lock the buffer during summarization to prevent new transcripts from being appended mid-processing. Storage failures on Google Drive due to quota limits or OAuth expiration must be handled gracefully by retrying uploads and prompting re-authentication when required.

Privacy risks include accidental server-side persistence through logs or crash dumps. Logging must avoid storing raw transcripts or audio payloads. All sensitive buffers must exist only in volatile memory. Reverse query processing must also avoid sending entire memory archives to the model; only relevant filtered summaries should be used as context to reduce exposure and improve efficiency.

What Must Not Be Done

The mobile app must not directly call Sarvam AI APIs with embedded credentials. OpenClaw must not store transcripts or audio files on disk or in persistent databases. Summarization must not be triggered multiple times for the same hourly window, and buffer clearing must not occur before the client acknowledges receipt of the summary. Persistent memory artifacts must never be stored on the server; they must always be uploaded to the user’s Google Drive to preserve data ownership and privacy guarantees.


